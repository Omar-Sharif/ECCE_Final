\section{\textbf{Dataset Preparation}}
For the successful implementation of any machine learning algorithm dataset is the key. As Bengali is a low resource language it was a very challenging task for us to build a corpus which contains a large amount of suspicious and non suspicious text. We have collected non suspicious data from a pre-build corpus \cite{banglacorpus}, thanks to them. Suspicious data are collected from different online and offline resources.% Data stored in .txt format.
\par \vspace{0.3cm} 
\noindent
U.S. Department of Homeland Security \cite{homesc} and Berwyn Police Department \cite{bpd} define some properties of suspicious activity. We may consider a text as suspicious if it has one of the following features,
\begin{itemize}
    \item Texts contain words which hurt our religious feelings.\vspace{0.2cm} 
    \item Texts which provoke people against government.\vspace{0.2cm} 
    \item Texts which provoke people against law enforcement agencies.\vspace{0.2cm} 
    \item Texts which motivate people in terrorist events.\vspace{0.2cm} 
    \item Texts which provoke a community without any reason.\vspace{0.2cm} 
    \item Texts which instigate our political parties. 
\end{itemize}
 \par \vspace{0.3cm}
 \noindent
 Most of our suspicious data about religion are collected from online blogs \cite{nastikya, dhormo, istishon}. Suspicious data about politics are collected from websites of different newspaper \cite{palo, kk, juga}. Data is also collected from different public pages of Facebook \cite{bash}. Table \ref{data} represents the statistics of data used for our model.
 
 \renewcommand{\arraystretch}{1.3}
\begin{table}[h!]
\begin{center}
\caption{Data Summary}
\begin{tabular}{||m{4cm} | m{1.7cm}| m{1.7cm}||}
\hline
    & Training set & Testing set \\
\hline
\hline
     Number of documents & 1500 & 500 \\
\hline
    Number of sentences & 6744 & 2247\\
\hline
    Number of words & 26973 & 8991\\
\hline
    Total unique words & 3250 & 1045\\
\hline

\end{tabular}
\label{data}
\end{center}
\end{table}
\noindent
In order to classify the texts, we have fed our collected documents to our classifier model. As dataset is collected manually it may have some inconsistencies.